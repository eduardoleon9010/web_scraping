{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìà Extracci√≥n de datos de acciones usando Web Scraping\n",
        "\n",
        "¬°Prep√°rate para una emocionante misi√≥n de an√°lisis financiero! üïµÔ∏è‚Äç‚ôÇÔ∏è‚ú® En este ejercicio, te adentrar√°s en el fascinante mundo del **web scraping** para obtener datos financieros hist√≥ricos directamente desde una p√°gina web. No todo est√° disponible a trav√©s de una API, as√≠ que es hora de poner manos a la obra. üöÄ\n",
        "\n",
        "üõ† ***¬øQu√© har√°s?***\n",
        "\n",
        "üìä 1. **Extraer datos hist√≥ricos de acciones** : Usar√°s la poderosa biblioteca **BeautifulSoup** para explorar y obtener informaci√≥n relevante desde una p√°gina web.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "¬°Listo para el desaf√≠o! üéØ\n"
      ],
      "metadata": {
        "id": "13PCkaadUdvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö Tabla de contenidos\n",
        "\n",
        "¬°Sigue este emocionante recorrido para convertir datos financieros en conocimiento! üé¢üíº\n",
        "\n",
        "1. üîç **Extracci√≥n de Datos con BeautifulSoup**\n",
        "   - Descargar una p√°gina web usando la biblioteca Requests üåê\n",
        "   - Analizar el HTML de una p√°gina web con BeautifulSoup üïµÔ∏è‚Äç‚ôÇÔ∏è\n",
        "   - Extraer datos y construir un DataFrame üìä\n",
        "\n",
        "2. üêº **Extracci√≥n de Datos usando Pandas**\n",
        "   - Aprende a manejar datos estructurados directamente con **pandas** para facilitar el an√°lisis. üìú\n",
        "\n",
        "3. üí™ **Ejercicio**\n",
        "   - ¬°Ponte a prueba! Practica lo aprendido con un desaf√≠o interactivo. üéØ\n"
      ],
      "metadata": {
        "id": "DILVDwBJU7MO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ú® **1. Instalaci√≥n de librer√≠as**  \n",
        "Ejecuta este bloque en Colab para instalar las dependencias necesarias.  \n",
        "\n",
        "```python\n",
        "# Instalar las librer√≠as necesarias\n",
        "!pip install pandas\n",
        "!pip install requests\n",
        "!pip install bs4\n",
        "\n"
      ],
      "metadata": {
        "id": "DgEqza4_WPbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install requests\n",
        "!pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-G6em3NWSN3",
        "outputId": "c83bf186-7807-45ea-807c-1628c062027a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Collecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.6)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.2\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.10/dist-packages (1.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib) (0.5.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (5.3.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üêç **2. Importar las librer√≠as**\n",
        "\n",
        "Aseg√∫rese de importar las librer√≠as correctamente antes de continuar. Tambi√©n ignoraremos las advertencias para mantener limpio el entorno."
      ],
      "metadata": {
        "id": "V_DumMjeWU9j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RLQuDwzbUc5o"
      },
      "outputs": [],
      "source": [
        "# Importar librer√≠as esenciales\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "import yfinance as yf\n",
        "\n",
        "# Ignorar advertencias\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üåê **3. Definir la URL del Sitio Web**\n",
        "Vamos a extraer los datos hist√≥ricos de la acci√≥n de Netflix (NFLX) desde Yahoo Finance ."
      ],
      "metadata": {
        "id": "6K5RCflcWgMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir el s√≠mbolo de la acci√≥n\n",
        "ticker = \"NFLX\"\n",
        "\n",
        "# Descargar datos hist√≥ricos de Netflix\n",
        "data = yf.download(ticker, period=\"1y\", interval=\"1d\")  # 1 a√±o de datos diarios\n",
        "\n",
        "# Mostrar los primeros 5 datos\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biEMrYxlWlG8",
        "outputId": "8a7c801a-5559-49ea-d7cc-36f198edd3b9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price                       Adj Close       Close        High         Low  \\\n",
            "Ticker                           NFLX        NFLX        NFLX        NFLX   \n",
            "Date                                                                        \n",
            "2023-11-28 00:00:00+00:00  479.000000  479.000000  480.500000  475.950012   \n",
            "2023-11-29 00:00:00+00:00  477.190002  477.190002  480.989990  474.489990   \n",
            "2023-11-30 00:00:00+00:00  473.970001  473.970001  478.589996  470.420013   \n",
            "2023-12-01 00:00:00+00:00  465.739990  465.739990  475.230011  464.600006   \n",
            "2023-12-04 00:00:00+00:00  453.899994  453.899994  461.200012  451.200012   \n",
            "\n",
            "Price                            Open   Volume  \n",
            "Ticker                           NFLX     NFLX  \n",
            "Date                                            \n",
            "2023-11-28 00:00:00+00:00  478.109985  2890200  \n",
            "2023-11-29 00:00:00+00:00  479.000000  2855500  \n",
            "2023-11-30 00:00:00+00:00  475.309998  4287300  \n",
            "2023-12-01 00:00:00+00:00  473.170013  4338100  \n",
            "2023-12-04 00:00:00+00:00  460.989990  5157700  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üìã **4. Enviar una solicitud HTTP**\n",
        "Usaremos la librer√≠a requests para obtener el contenido HTML de la p√°gina web."
      ],
      "metadata": {
        "id": "6b-i_vxJWoT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enviar una solicitud HTTP para obtener el contenido HTML\n",
        "data = requests.get(url).text\n",
        "\n",
        "# Mostrar parte del contenido HTML (opcional, para inspecci√≥n)\n",
        "print(data[:500])  # Imprimir los primeros 500 caracteres"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYu1jH1_Wy8A",
        "outputId": "79fd2d76-f44d-42d7-bb1c-82e88f58bde6"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html>\n",
            "  <html lang=\"en-us\"><head>\n",
            "  <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n",
            "      <meta charset=\"utf-8\">\n",
            "      <title>Yahoo</title>\n",
            "      <meta name=\"viewport\" content=\"width=device-width,initial-scale=1,minimal-ui\">\n",
            "      <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\n",
            "      <style>\n",
            "  html {\n",
            "      height: 100%;\n",
            "  }\n",
            "  body {\n",
            "      background: #fafafc url(https://s.yimg.com/nn/img/sad-panda-201402200631.png) 50% 50%;\n",
            "      background-size: cove\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üß†**5. Analizar el HTML con BeautifulSoup**\n",
        "El an√°lisis del HTML permite estructurar y manipular los datos de forma efectiva."
      ],
      "metadata": {
        "id": "w4XsO5ZlW_XH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un objeto BeautifulSoup para analizar el HTML\n",
        "soup = BeautifulSoup(data, 'html.parser')"
      ],
      "metadata": {
        "id": "cc4TM41mXFx4"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üîç **6. Identificar la Tabla HTML**\n",
        "\n",
        "Identificaremos las etiquetas <**table**> y <**tbody**> donde se almacenan los datos. Creamos un DataFrame vac√≠o para guardar la informaci√≥n extra√≠da."
      ],
      "metadata": {
        "id": "M61dYRd-XJbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear un DataFrame vac√≠o con las columnas necesarias\n",
        "netflix_data = pd.DataFrame(columns=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])"
      ],
      "metadata": {
        "id": "4xKm2oLUXVRr"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üõ† **7. Extraer los Datos de la Tabla**\n",
        "Extraemos las filas ( <tr>) y celdas ( <td>) para completar el DataFrame con los datos relevantes."
      ],
      "metadata": {
        "id": "aKb8EovQXYpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Localizar el cuerpo de la tabla\n",
        "table_body = soup.find(\"tbody\")\n",
        "\n",
        "# Iterar sobre las filas de la tabla\n",
        "for row in table_body.find_all('tr'):\n",
        "    col = row.find_all('td')\n",
        "    if len(col) > 1:  # Ignorar filas vac√≠as\n",
        "        date = col[0].text\n",
        "        open_ = col[1].text\n",
        "        high = col[2].text\n",
        "        low = col[3].text\n",
        "        close = col[4].text\n",
        "        volume = col[6].text\n",
        "\n",
        "        # Agregar datos al DataFrame\n",
        "        netflix_data = pd.concat([netflix_data, pd.DataFrame({\n",
        "            \"Date\": [date],\n",
        "            \"Open\": [open_],\n",
        "            \"High\": [high],\n",
        "            \"Low\": [low],\n",
        "            \"Close\": [close],\n",
        "            \"Volume\": [volume]\n",
        "        })], ignore_index=True)"
      ],
      "metadata": {
        "id": "Zf4QcZWmXemO"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üñ® **8. Mostrar los datos extra√≠dos**\n",
        "Verifica los datos extra√≠dos imprimiendo las primeras filas del DataFrame."
      ],
      "metadata": {
        "id": "1uA62xO_XhuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las primeras filas del DataFrame\n",
        "print(netflix_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiNQ3_h6XoEJ",
        "outputId": "8377f194-958f-4eeb-9c8e-566e5bda8508"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Date, Open, High, Low, Close, Volume]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##üêº **9. Extracci√≥n alternativa con Pandas**\n",
        "Pandas tambi√©n permite extraer directamente tablas de una p√°gina web utilizando pd.read_html()."
      ],
      "metadata": {
        "id": "5EpU1tL1Xq2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener datos hist√≥ricos de Netflix usando el s√≠mbolo de cotizaci√≥n \"NFLX\"\n",
        "nflx = yf.Ticker(\"NFLX\")\n",
        "nflx_data = nflx.history(period=\"1y\")  # Datos del √∫ltimo a√±o\n",
        "\n",
        "# Mostrar las primeras 5 filas de los datos hist√≥ricos\n",
        "print(nflx_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csefzyTmXx0n",
        "outputId": "227263f5-c8f4-4098-86af-fd903a1427b8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 Open        High         Low       Close  \\\n",
            "Date                                                                        \n",
            "2023-11-28 00:00:00-05:00  478.109985  480.500000  475.950012  479.000000   \n",
            "2023-11-29 00:00:00-05:00  479.000000  480.989990  474.489990  477.190002   \n",
            "2023-11-30 00:00:00-05:00  475.309998  478.589996  470.420013  473.970001   \n",
            "2023-12-01 00:00:00-05:00  473.170013  475.230011  464.600006  465.739990   \n",
            "2023-12-04 00:00:00-05:00  460.989990  461.200012  451.200012  453.899994   \n",
            "\n",
            "                            Volume  Dividends  Stock Splits  \n",
            "Date                                                         \n",
            "2023-11-28 00:00:00-05:00  2890200        0.0           0.0  \n",
            "2023-11-29 00:00:00-05:00  2855500        0.0           0.0  \n",
            "2023-11-30 00:00:00-05:00  4287300        0.0           0.0  \n",
            "2023-12-01 00:00:00-05:00  4338100        0.0           0.0  \n",
            "2023-12-04 00:00:00-05:00  5157700        0.0           0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar datos hist√≥ricos de AMZN\n",
        "amzn = yf.Ticker(\"AMZN\")\n",
        "amazon_data = amzn.history(period=\"1y\")  # Puedes cambiar el per√≠odo seg√∫n lo necesites\n",
        "\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uIDZpfojYLk",
        "outputId": "03ce2963-9226-498a-ca7b-1eef680e2a73"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 Open        High         Low       Close  \\\n",
            "Date                                                                        \n",
            "2023-11-28 00:00:00-05:00  146.979996  147.600006  145.529999  147.029999   \n",
            "2023-11-29 00:00:00-05:00  147.850006  148.539993  145.970001  146.320007   \n",
            "2023-11-30 00:00:00-05:00  144.759995  146.929993  144.330002  146.089996   \n",
            "2023-12-01 00:00:00-05:00  146.000000  147.250000  145.550003  147.029999   \n",
            "2023-12-04 00:00:00-05:00  145.250000  145.350006  142.809998  144.839996   \n",
            "...                               ...         ...         ...         ...   \n",
            "2024-11-21 00:00:00-05:00  203.490005  203.490005  195.750000  198.380005   \n",
            "2024-11-22 00:00:00-05:00  198.250000  199.259995  196.750000  197.119995   \n",
            "2024-11-25 00:00:00-05:00  199.279999  201.949997  199.000000  201.449997   \n",
            "2024-11-26 00:00:00-05:00  201.899994  208.000000  201.789993  207.860001   \n",
            "2024-11-27 00:00:00-05:00  206.979996  207.639999  205.050003  205.740005   \n",
            "\n",
            "                             Volume  Dividends  Stock Splits  \n",
            "Date                                                          \n",
            "2023-11-28 00:00:00-05:00  42711700        0.0           0.0  \n",
            "2023-11-29 00:00:00-05:00  40610900        0.0           0.0  \n",
            "2023-11-30 00:00:00-05:00  65814000        0.0           0.0  \n",
            "2023-12-01 00:00:00-05:00  39924600        0.0           0.0  \n",
            "2023-12-04 00:00:00-05:00  48294200        0.0           0.0  \n",
            "...                             ...        ...           ...  \n",
            "2024-11-21 00:00:00-05:00  58800000        0.0           0.0  \n",
            "2024-11-22 00:00:00-05:00  31530800        0.0           0.0  \n",
            "2024-11-25 00:00:00-05:00  40685700        0.0           0.0  \n",
            "2024-11-26 00:00:00-05:00  41673700        0.0           0.0  \n",
            "2024-11-27 00:00:00-05:00  28061600        0.0           0.0  \n",
            "\n",
            "[253 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio:**\n",
        "\n",
        "1. ¬øCu√°les son los nombres de las columnas en el DataFrame?"
      ],
      "metadata": {
        "id": "qk4pHSxPk86r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribe aqui tu codigo\n"
      ],
      "metadata": {
        "id": "InPNdfWtk9Bp"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<details><summary>Haz clic aqu√≠ para ver la soluci√≥n üí°</summary>\n",
        "\n",
        "```python\n",
        "print(\"Nombres de las columnas:\", amazon_data.columns.tolist())\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "Ww1v4Z7wmkQC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. ¬øCu√°l es el valor de ***Open*** la √∫ltima fila del DataFrame?"
      ],
      "metadata": {
        "id": "I6sIBCKEmzWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribe aqui tu codigo\n"
      ],
      "metadata": {
        "id": "wQ-8IJdHm4Ju"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details><summary>Haz clic aqu√≠ para ver la soluci√≥n üí°</summary>\n",
        "\n",
        "```python\n",
        "last_open = amazon_data.iloc[-1]['Open']\n",
        "print(\"El valor de 'Open' en la √∫ltima fila es:\", last_open)\n",
        "```\n",
        "</details>"
      ],
      "metadata": {
        "id": "QzMOrgs_nCI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autor**\n",
        "\n",
        "<a href=\"https://www.linkedin.com/in/mbaeduleon/\">Ing. David Eduardo Le√≥n</a> üåü\n",
        "\n",
        "## Otros colaboradores\n",
        "\n",
        "<a href=\"https://www.linkedin.com\"> </a> ü§ù\n",
        "\n",
        "## Registro de cambios\n",
        "\n",
        "| Fecha (AAAA-MM-DD) | Versi√≥n | Cambiado por | Descripci√≥n del cambio            |\n",
        "| ------------------- | ------- | ------------ | --------------------------------- |\n",
        "|                     |         |              |                                   |\n",
        "|                     |         |              |                                   |"
      ],
      "metadata": {
        "id": "1OMZZJy0oVru"
      }
    }
  ]
}